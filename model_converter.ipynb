{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5241f677",
   "metadata": {},
   "source": [
    "# üìå Model Converter Notebook\n",
    "\n",
    "Questo notebook guida il processo di conversione del modello TensorFlow in TensorFlow Lite con l'aggiunta di metadati e compatibilit√† con l'API di Object Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03991851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ **Avvio dell'analisi del modello TensorFlow**\n",
      "\n",
      "üìå **Firme disponibili nel modello:**\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ serving_default\n",
      "\n",
      "üìå **Analisi del MetaGraph**\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìå **Tensori di Input**\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: images\n",
      "   Nome Tecnico: serving_default_images:0\n",
      "   Tipo: uint8\n",
      "   Dimensione: 1x448x448x3\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìå **Tensori di Output**\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: raw_detection_scores\n",
      "   Nome Tecnico: StatefulPartitionedCall:7\n",
      "   Tipo: float32\n",
      "   Dimensione: 1x12804x2\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: detection_multiclass_scores\n",
      "   Nome Tecnico: StatefulPartitionedCall:3\n",
      "   Tipo: float32\n",
      "   Dimensione: 1x100x2\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: detection_scores\n",
      "   Nome Tecnico: StatefulPartitionedCall:4\n",
      "   Tipo: float32\n",
      "   Dimensione: 1x100\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: detection_boxes\n",
      "   Nome Tecnico: StatefulPartitionedCall:1\n",
      "   Tipo: float32\n",
      "   Dimensione: 1x100x4\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: num_detections\n",
      "   Nome Tecnico: StatefulPartitionedCall:5\n",
      "   Tipo: float32\n",
      "   Dimensione: 1\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: raw_detection_boxes\n",
      "   Nome Tecnico: StatefulPartitionedCall:6\n",
      "   Tipo: float32\n",
      "   Dimensione: 1x12804x4\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: detection_classes\n",
      "   Nome Tecnico: StatefulPartitionedCall:2\n",
      "   Tipo: float32\n",
      "   Dimensione: 1x100\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ Nome Tensore: detection_anchor_indices\n",
      "   Nome Tecnico: StatefulPartitionedCall:0\n",
      "   Tipo: float32\n",
      "   Dimensione: 1x100\n",
      "   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìå **Dettagli della firma 'serving_default'**\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "\n",
      "üìå **Inputs della Firma**\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ images: TensorSpec(shape=(1, 448, 448, 3), dtype=tf.uint8, name='images')\n",
      "\n",
      "üìå **Outputs della Firma**\n",
      "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
      "üîπ detection_scores: TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_scores')\n",
      "üîπ raw_detection_boxes: TensorSpec(shape=(1, 12804, 4), dtype=tf.float32, name='raw_detection_boxes')\n",
      "üîπ detection_anchor_indices: TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_anchor_indices')\n",
      "üîπ detection_boxes: TensorSpec(shape=(1, 100, 4), dtype=tf.float32, name='detection_boxes')\n",
      "üîπ detection_multiclass_scores: TensorSpec(shape=(1, 100, 2), dtype=tf.float32, name='detection_multiclass_scores')\n",
      "üîπ num_detections: TensorSpec(shape=(1,), dtype=tf.float32, name='num_detections')\n",
      "üîπ raw_detection_scores: TensorSpec(shape=(1, 12804, 2), dtype=tf.float32, name='raw_detection_scores')\n",
      "üîπ detection_classes: TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_classes')\n",
      "\n",
      "‚úÖ **Analisi completata con successo!** üéâ\n"
     ]
    }
   ],
   "source": [
    "# Questa cella definisce una funzione analyze_saved_model(saved_model_dir) che analizza un modello TensorFlow salvato \n",
    "# e stampa dettagli strutturati relativi a:\n",
    "#\n",
    "# Firme disponibili: Mostra le firme disponibili nel modello.\n",
    "# MetaGraph: Estrae e analizza la firma serving_default del modello.\n",
    "# Tensori di input: Mostra i dettagli di nome, tipo, dimensione e forma dei tensori di input.\n",
    "# Tensori di output: Mostra i dettagli di nome, tipo, dimensione e forma dei tensori di output.\n",
    "# Firma serving_default: Stampa dettagli completi degli input e degli output strutturati della firma.\n",
    "# In caso di errore, il codice cattura e stampa l'eccezione.\n",
    "\n",
    "# Iniziamo importando le librerie necessarie\n",
    "import tensorflow as tf\n",
    "from tensorflow import lite\n",
    "from tensorflow.python.tools import saved_model_utils\n",
    "import os\n",
    "\n",
    "# Definizione del percorso del modello salvato\n",
    "SAVED_MODEL_PATH = \"models/saved_model\"\n",
    "\n",
    "def analyze_saved_model(saved_model_dir):\n",
    "    \"\"\" Analizza il modello salvato e stampa le informazioni dettagliate. \"\"\"\n",
    "    try:\n",
    "        # Carica il modello salvato\n",
    "        model = tf.saved_model.load(saved_model_dir)\n",
    "\n",
    "        # Mostra le firme disponibili\n",
    "        print(\"\\nüìå **Firme disponibili nel modello:**\")\n",
    "        print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        signatures = list(model.signatures.keys())\n",
    "        for sig in signatures:\n",
    "            print(f\"üîπ {sig}\")\n",
    "\n",
    "        # Analizza il MetaGraph\n",
    "        print(\"\\nüìå **Analisi del MetaGraph**\")\n",
    "        print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        meta_graph = saved_model_utils.get_meta_graph_def(saved_model_dir, tag_set=\"serve\")\n",
    "        signature_def = meta_graph.signature_def[\"serving_default\"]\n",
    "\n",
    "        # Analizza gli input\n",
    "        print(\"\\nüìå **Tensori di Input**\")\n",
    "        print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        for key, tensor_info in signature_def.inputs.items():\n",
    "            shape = \"x\".join(str(dim.size) if dim.size >= 0 else \"?\" for dim in tensor_info.tensor_shape.dim)\n",
    "            print(f\"üîπ Nome Tensore: {key}\")\n",
    "            print(f\"   Nome Tecnico: {tensor_info.name}\")\n",
    "            print(f\"   Tipo: {tf.dtypes.as_dtype(tensor_info.dtype).name}\")\n",
    "            print(f\"   Dimensione: {shape}\")\n",
    "            print(\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "\n",
    "        # Analizza gli output\n",
    "        print(\"\\nüìå **Tensori di Output**\")\n",
    "        print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        for key, tensor_info in signature_def.outputs.items():\n",
    "            shape = \"x\".join(str(dim.size) if dim.size >= 0 else \"?\" for dim in tensor_info.tensor_shape.dim)\n",
    "            print(f\"üîπ Nome Tensore: {key}\")\n",
    "            print(f\"   Nome Tecnico: {tensor_info.name}\")\n",
    "            print(f\"   Tipo: {tf.dtypes.as_dtype(tensor_info.dtype).name}\")\n",
    "            print(f\"   Dimensione: {shape}\")\n",
    "            print(\"   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "\n",
    "        # Analizza la firma \"serving_default\"\n",
    "        print(\"\\nüìå **Dettagli della firma 'serving_default'**\")\n",
    "        print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        signature = model.signatures['serving_default']\n",
    "        input_details = signature.structured_input_signature\n",
    "        output_details = signature.structured_outputs\n",
    "\n",
    "        print(\"\\nüìå **Inputs della Firma**\")\n",
    "        print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        for k, v in input_details[1].items():\n",
    "            print(f\"üîπ {k}: {v}\")\n",
    "\n",
    "        print(\"\\nüìå **Outputs della Firma**\")\n",
    "        print(\"‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\")\n",
    "        for k, v in output_details.items():\n",
    "            print(f\"üîπ {k}: {v}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Errore durante l'analisi del modello: {e}\")\n",
    "\n",
    "# Esegui l'analisi del modello\n",
    "print(\"\\nüöÄ **Avvio dell'analisi del modello TensorFlow**\")\n",
    "analyze_saved_model(SAVED_MODEL_PATH)\n",
    "\n",
    "print(\"\\n‚úÖ **Analisi completata con successo!** üéâ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2dbac083-5820-46b6-b865-313d2f9beebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento del modello originale da: models/saved_model\n",
      "Salvataggio del nuovo modello con signature personalizzata in: models/custom_model\n",
      "INFO:tensorflow:Assets written to: models/custom_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: models/custom_model\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuovo modello salvato in: models/custom_model\n",
      "\n",
      "üìå Verifica del nuovo modello salvato\n",
      "\n",
      "üìå Dettagli della firma 'filtered_inference'\n",
      "== Inputs ==\n",
      "üîπ images: TensorSpec(shape=(1, 448, 448, 3), dtype=tf.uint8, name='images')\n",
      "\n",
      "== Outputs ==\n",
      "üîπ detection_scores: TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_scores')\n",
      "üîπ detection_classes: TensorSpec(shape=(1, 100), dtype=tf.float32, name='detection_classes')\n",
      "üîπ detection_boxes: TensorSpec(shape=(1, 100, 4), dtype=tf.float32, name='detection_boxes')\n",
      "üîπ num_detections: TensorSpec(shape=(1,), dtype=tf.float32, name='num_detections')\n"
     ]
    }
   ],
   "source": [
    "# Questa cella definisce una nuova funzione di inferenza filtered_inference per rendere il modello compatibile con l‚ÄôAPI \n",
    "# di Object Detection di TensorFlow. La funzione seleziona i 4 output richiesti dall‚ÄôAPI tra gli 8 output disponibili \n",
    "# nel modello originale.\n",
    "#\n",
    "# - Input: Accetta lo stesso input dell'inferenza originale (images con forma (1, 448, 448, 3), tipo uint8).\n",
    "# - Output: Restituisce un sottoinsieme degli output originali:\n",
    "#   1. detection_boxes\n",
    "#   2. detection_classes\n",
    "#   3. detection_scores\n",
    "#   4. num_detections\n",
    "#\n",
    "# Infine, il modello personalizzato viene salvato con una nuova firma di inferenza e, in caso di successo, \n",
    "# vengono stampati i dettagli dei tensori del nuovo modello.\n",
    "\n",
    "# Percorso al modello originale SavedModel\n",
    "SAVED_MODEL_PATH = \"models/saved_model\"\n",
    "\n",
    "# Percorso per salvare il nuovo modello\n",
    "NEW_SAVED_MODEL_PATH = \"models/custom_model\"\n",
    "\n",
    "# Caricamento del modello originale\n",
    "print(f\"Caricamento del modello originale da: {SAVED_MODEL_PATH}\")\n",
    "model = tf.saved_model.load(SAVED_MODEL_PATH)\n",
    "\n",
    "# Estrai la signature originale\n",
    "original_infer = model.signatures['serving_default']\n",
    "\n",
    "# Definizione della nuova funzione di inferenza con output in formato flat list\n",
    "@tf.function(input_signature=[tf.TensorSpec(shape=(1, 448, 448, 3), dtype=tf.uint8, name='images')])\n",
    "def filtered_inference(*args, **kwargs):\n",
    "    # Esegui l'inferenza originale\n",
    "    original_outputs = original_infer(*args, **kwargs)\n",
    "    # Restituisci gli output\n",
    "    return {\n",
    "        'detection_boxes': original_outputs['detection_boxes'],\n",
    "        'detection_classes': original_outputs['detection_classes'],\n",
    "        'detection_scores': original_outputs['detection_scores'],\n",
    "        'num_detections': original_outputs['num_detections']\n",
    "    }\n",
    "\n",
    "# Salvataggio del nuovo modello con la signature personalizzata\n",
    "print(f\"Salvataggio del nuovo modello con signature personalizzata in: {NEW_SAVED_MODEL_PATH}\")\n",
    "tf.saved_model.save(\n",
    "    model,\n",
    "    NEW_SAVED_MODEL_PATH,\n",
    "    signatures={'filtered_inference': filtered_inference.get_concrete_function()}\n",
    ")\n",
    "print(f\"Nuovo modello salvato in: {NEW_SAVED_MODEL_PATH}\")\n",
    "\n",
    "# Verifica del nuovo modello: Stampa dei dettagli dei tensori\n",
    "print(\"\\nüìå Verifica del nuovo modello salvato\")\n",
    "try:\n",
    "    # Carica il nuovo modello salvato\n",
    "    new_model = tf.saved_model.load(NEW_SAVED_MODEL_PATH)\n",
    "    \n",
    "    # Accedi alla nuova firma 'filtered_inference'\n",
    "    new_signature = new_model.signatures['filtered_inference']\n",
    "    \n",
    "    # Recupera i dettagli di input e output della firma\n",
    "    new_input_details = new_signature.structured_input_signature\n",
    "    new_output_details = new_signature.structured_outputs\n",
    "\n",
    "    # Stampa i dettagli degli input\n",
    "    print(\"\\nüìå Dettagli della firma 'filtered_inference'\")\n",
    "    print(\"== Inputs ==\")\n",
    "    for key, value in new_input_details[1].items():\n",
    "        print(f\"üîπ {key}: {value}\")\n",
    "    \n",
    "    # Stampa i dettagli degli output\n",
    "    print(\"\\n== Outputs ==\")\n",
    "    for key, value in new_output_details.items():\n",
    "        print(f\"üîπ {key}: {value}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Errore durante la verifica del nuovo modello: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e68fd81-3054-4a26-a31d-4ea6955af5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Conversione del modello SENZA quantizzazione...\n",
      "‚úÖ Modello TFLite salvato in: models/custom_model.tflite\n",
      "\n",
      "üîÑ Conversione del modello CON quantizzazione dinamica...\n",
      "‚úÖ Modello TFLite salvato in: models/custom_model_quantized.tflite\n",
      "\n",
      "üîÑ Conversione del modello CON quantizzazione float16...\n",
      "‚úÖ Modello TFLite salvato in: models/custom_model_float16.tflite\n",
      "\n",
      "üìè Dimensioni dei modelli:\n",
      "üöÄ Modello SENZA quantizzazione: 11116.20 KB\n",
      "‚ö° Modello CON quantizzazione dinamica: 2980.32 KB\n",
      "üîç Modello CON quantizzazione float16: 5654.55 KB\n",
      "\n",
      "‚úÖ Conversione completata per tutti i modelli.\n"
     ]
    }
   ],
   "source": [
    "# Conversione del modello SavedModel in TFLite con diverse tecniche di quantizzazione\n",
    "# Questa cella converte il modello SavedModel in tre versioni:\n",
    "# - Senza quantizzazione\n",
    "# - Con quantizzazione dinamica\n",
    "# - Con quantizzazione float16\n",
    "\n",
    "# Percorsi dei modelli\n",
    "SAVED_MODEL_PATH = \"models/custom_model\"\n",
    "TFLITE_MODEL_PATH = \"models/custom_model.tflite\"\n",
    "TFLITE_QUANT_MODEL_PATH = \"models/custom_model_quantized.tflite\"\n",
    "TFLITE_FLOAT16_MODEL_PATH = \"models/custom_model_float16.tflite\"\n",
    "\n",
    "# Funzione per convertire il modello in TFLite\n",
    "def convert_to_tflite(saved_model_path, tflite_model_path, quantization_type=None):\n",
    "    \"\"\"\n",
    "    Converte un modello SavedModel in TFLite.\n",
    "\n",
    "    Args:\n",
    "        saved_model_path (str): Percorso del modello SavedModel.\n",
    "        tflite_model_path (str): Percorso dove salvare il modello TFLite.\n",
    "        quantization_type (str, opzionale): Tipo di quantizzazione (\"dynamic\", \"float16\" o None).\n",
    "    \"\"\"\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_path)\n",
    "    \n",
    "    if quantization_type == \"dynamic\":\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    elif quantization_type == \"float16\":\n",
    "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "        converter.target_spec.supported_types = [tf.float16]\n",
    "    \n",
    "    tflite_model = converter.convert()\n",
    "    with open(tflite_model_path, 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "    print(f\"‚úÖ Modello TFLite salvato in: {tflite_model_path}\")\n",
    "\n",
    "# Conversione del modello in TFLite senza quantizzazione\n",
    "print(\"üîÑ Conversione del modello SENZA quantizzazione...\")\n",
    "convert_to_tflite(SAVED_MODEL_PATH, TFLITE_MODEL_PATH, quantization_type=None)\n",
    "\n",
    "# Conversione del modello in TFLite con quantizzazione dinamica\n",
    "print(\"\\nüîÑ Conversione del modello CON quantizzazione dinamica...\")\n",
    "convert_to_tflite(SAVED_MODEL_PATH, TFLITE_QUANT_MODEL_PATH, quantization_type=\"dynamic\")\n",
    "\n",
    "# Conversione del modello in TFLite con quantizzazione float16\n",
    "print(\"\\nüîÑ Conversione del modello CON quantizzazione float16...\")\n",
    "convert_to_tflite(SAVED_MODEL_PATH, TFLITE_FLOAT16_MODEL_PATH, quantization_type=\"float16\")\n",
    "\n",
    "# Funzione per calcolare la dimensione del file\n",
    "def get_model_size(file_path):\n",
    "    size_in_kb = os.path.getsize(file_path) / 1024\n",
    "    return size_in_kb\n",
    "\n",
    "# Stampa delle dimensioni dei modelli\n",
    "print(\"\\nüìè Dimensioni dei modelli:\")\n",
    "size_no_quant = get_model_size(TFLITE_MODEL_PATH)\n",
    "size_quant_dynamic = get_model_size(TFLITE_QUANT_MODEL_PATH)\n",
    "size_float16 = get_model_size(TFLITE_FLOAT16_MODEL_PATH)\n",
    "\n",
    "print(f\"üöÄ Modello SENZA quantizzazione: {size_no_quant:.2f} KB\")\n",
    "print(f\"‚ö° Modello CON quantizzazione dinamica: {size_quant_dynamic:.2f} KB\")\n",
    "print(f\"üîç Modello CON quantizzazione float16: {size_float16:.2f} KB\")\n",
    "\n",
    "print(\"\\n‚úÖ Conversione completata per tutti i modelli.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f13472d7-b375-4c71-8f60-960e307d119c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Modello con metadati salvato in: models/plate_recognizer.tflite\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h2 style='color: green;'>üìå Analisi dei Metadati del Modello</h2>\n",
       "            <div style=\"border: 1px solid blue; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
       "                <h3 style=\"color: blue;\">üìÑ Dettagli Generali</h3>\n",
       "                <pre style=\"font-size: 14px;\">\"ObjectDetector\"</pre>\n",
       "            </div>\n",
       "            \n",
       "            <div style=\"border: 1px solid purple; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
       "                <h3 style=\"color: purple;\">üì• Input Tensor Metadata</h3>\n",
       "                <pre style=\"font-size: 14px;\">{\n",
       "    \"name\": \"image\",\n",
       "    \"description\": \"Input image to be detected.\",\n",
       "    \"content\": {\n",
       "        \"content_properties_type\": \"ImageProperties\",\n",
       "        \"content_properties\": {\n",
       "            \"color_space\": \"RGB\"\n",
       "        }\n",
       "    },\n",
       "    \"process_units\": [\n",
       "        {\n",
       "            \"options_type\": \"NormalizationOptions\",\n",
       "            \"options\": {\n",
       "                \"mean\": [\n",
       "                    127.5\n",
       "                ],\n",
       "                \"std\": [\n",
       "                    127.5\n",
       "                ]\n",
       "            }\n",
       "        }\n",
       "    ],\n",
       "    \"stats\": {\n",
       "        \"max\": [\n",
       "            255.0\n",
       "        ],\n",
       "        \"min\": [\n",
       "            0.0\n",
       "        ]\n",
       "    }\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            <div style=\"border: 1px solid orange; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
       "                <h3 style=\"color: orange;\">üì§ Output Tensor Metadata: location</h3>\n",
       "                <pre style=\"font-size: 14px;\">{\n",
       "    \"name\": \"location\",\n",
       "    \"description\": \"The locations of the detected boxes.\",\n",
       "    \"content\": {\n",
       "        \"content_properties_type\": \"BoundingBoxProperties\",\n",
       "        \"content_properties\": {\n",
       "            \"index\": [\n",
       "                1,\n",
       "                0,\n",
       "                3,\n",
       "                2\n",
       "            ],\n",
       "            \"type\": \"BOUNDARIES\"\n",
       "        },\n",
       "        \"range\": {\n",
       "            \"min\": 2,\n",
       "            \"max\": 2\n",
       "        }\n",
       "    },\n",
       "    \"stats\": {}\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            <div style=\"border: 1px solid orange; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
       "                <h3 style=\"color: orange;\">üì§ Output Tensor Metadata: number of detections</h3>\n",
       "                <pre style=\"font-size: 14px;\">{\n",
       "    \"name\": \"number of detections\",\n",
       "    \"description\": \"The number of the detected boxes.\",\n",
       "    \"content\": {\n",
       "        \"content_properties_type\": \"FeatureProperties\",\n",
       "        \"content_properties\": {}\n",
       "    },\n",
       "    \"stats\": {}\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            <div style=\"border: 1px solid orange; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
       "                <h3 style=\"color: orange;\">üì§ Output Tensor Metadata: score</h3>\n",
       "                <pre style=\"font-size: 14px;\">{\n",
       "    \"name\": \"score\",\n",
       "    \"description\": \"The scores of the detected boxes.\",\n",
       "    \"content\": {\n",
       "        \"content_properties_type\": \"FeatureProperties\",\n",
       "        \"content_properties\": {},\n",
       "        \"range\": {\n",
       "            \"min\": 2,\n",
       "            \"max\": 2\n",
       "        }\n",
       "    },\n",
       "    \"stats\": {}\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            <div style=\"border: 1px solid orange; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
       "                <h3 style=\"color: orange;\">üì§ Output Tensor Metadata: category</h3>\n",
       "                <pre style=\"font-size: 14px;\">{\n",
       "    \"name\": \"category\",\n",
       "    \"description\": \"The categories of the detected boxes.\",\n",
       "    \"content\": {\n",
       "        \"content_properties_type\": \"FeatureProperties\",\n",
       "        \"content_properties\": {},\n",
       "        \"range\": {\n",
       "            \"min\": 2,\n",
       "            \"max\": 2\n",
       "        }\n",
       "    },\n",
       "    \"stats\": {},\n",
       "    \"associated_files\": [\n",
       "        {\n",
       "            \"name\": \"label_map.pbtxt\",\n",
       "            \"description\": \"Labels for categories that the model can recognize.\",\n",
       "            \"type\": \"TENSOR_VALUE_LABELS\"\n",
       "        }\n",
       "    ]\n",
       "}</pre>\n",
       "            </div>\n",
       "            \n",
       "            <div style=\"border: 1px solid red; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
       "                <h3 style=\"color: red;\">üìÇ File Associati</h3>\n",
       "                <pre style=\"font-size: 14px;\">üìé label_map.pbtxt</pre>\n",
       "            </div>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Scrittura e Analisi dei Metadati del Modello TFLite\n",
    "# Questa cella utilizza la Metadata Writer API di TensorFlow Lite per:\n",
    "# 1. Aggiungere i metadati necessari al modello non quantizzato per supportare l'API Object Detection di Android.\n",
    "# 2. Analizzare e visualizzare in modo chiaro i metadati aggiunti al modello.\n",
    "\n",
    "# ========================\n",
    "# Parte 1: Scrittura dei Metadati\n",
    "# ========================\n",
    "\n",
    "from tflite_support.metadata_writers import object_detector\n",
    "from tflite_support.metadata_writers import writer_utils\n",
    "\n",
    "# Definizione dei percorsi e parametri per il modello e i metadati\n",
    "ObjectDetectorWriter = object_detector.MetadataWriter\n",
    "_MODEL_PATH = \"models/custom_model.tflite\"  # Modello TFLite senza quantizzazione\n",
    "_LABEL_FILE = \"models/label_map.pbtxt\"          # File delle etichette per il modello\n",
    "_SAVE_TO_PATH = \"models/plate_recognizer.tflite\"  # Modello finale con metadati\n",
    "_INPUT_NORM_MEAN = 127.5                   # Parametro per la normalizzazione degli input\n",
    "_INPUT_NORM_STD = 127.5                    # Parametro per la normalizzazione degli input\n",
    "\n",
    "# Creazione del Metadata Writer per il modello\n",
    "writer = ObjectDetectorWriter.create_for_inference(\n",
    "    writer_utils.load_file(_MODEL_PATH), \n",
    "    [_INPUT_NORM_MEAN], \n",
    "    [_INPUT_NORM_STD],\n",
    "    [_LABEL_FILE]\n",
    ")\n",
    "\n",
    "# Popolazione dei metadati nel modello e salvataggio del modello finale\n",
    "writer_utils.save_file(writer.populate(), _SAVE_TO_PATH)\n",
    "print(f\"‚úÖ Modello con metadati salvato in: {_SAVE_TO_PATH}\")\n",
    "\n",
    "# ========================\n",
    "# Parte 2: Analisi e Visualizzazione dei Metadati\n",
    "# ========================\n",
    "\n",
    "import json\n",
    "from tflite_support import metadata\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Percorso del modello finale con metadati\n",
    "model_path = _SAVE_TO_PATH\n",
    "\n",
    "# Funzione per analizzare e stampare i metadati del modello in modo schematizzato e leggibile\n",
    "def display_model_metadata(model_path):\n",
    "    \"\"\"Analizza i metadati del modello TensorFlow Lite e li stampa in modo leggibile.\n",
    "    \n",
    "    Args:\n",
    "        model_path (str): Percorso al file del modello TFLite.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Creazione di un MetadataDisplayer per il modello specificato\n",
    "        displayer = metadata.MetadataDisplayer.with_model_file(model_path)\n",
    "        \n",
    "        # Estrazione dei metadati in formato JSON\n",
    "        metadata_json = displayer.get_metadata_json()\n",
    "        metadata_dict = json.loads(metadata_json)\n",
    "        \n",
    "        # Funzione per generare HTML colorato\n",
    "        def format_html_section(title, content, color=\"blue\"):\n",
    "            return f\"\"\"\n",
    "            <div style=\"border: 1px solid {color}; border-radius: 5px; padding: 10px; margin-bottom: 10px;\">\n",
    "                <h3 style=\"color: {color};\">{title}</h3>\n",
    "                <pre style=\"font-size: 14px;\">{content}</pre>\n",
    "            </div>\n",
    "            \"\"\"\n",
    "        \n",
    "        # Stampa del titolo\n",
    "        html_content = f\"<h2 style='color: green;'>üìå Analisi dei Metadati del Modello</h2>\"\n",
    "        \n",
    "        # Dettagli generali del modello\n",
    "        html_content += format_html_section(\"üìÑ Dettagli Generali\",\n",
    "                                             json.dumps(metadata_dict.get(\"name\", \"N/A\"), indent=4))\n",
    "        \n",
    "        # Input tensor metadata\n",
    "        input_metadata = metadata_dict[\"subgraph_metadata\"][0][\"input_tensor_metadata\"][0]\n",
    "        html_content += format_html_section(\"üì• Input Tensor Metadata\",\n",
    "                                             json.dumps(input_metadata, indent=4), color=\"purple\")\n",
    "        \n",
    "        # Output tensor metadata\n",
    "        for output_tensor in metadata_dict[\"subgraph_metadata\"][0][\"output_tensor_metadata\"]:\n",
    "            html_content += format_html_section(f\"üì§ Output Tensor Metadata: {output_tensor['name']}\",\n",
    "                                                 json.dumps(output_tensor, indent=4), color=\"orange\")\n",
    "        \n",
    "        # File associati\n",
    "        associated_files = displayer.get_packed_associated_file_list()\n",
    "        associated_files_section = \"\\n\".join([f\"üìé {file}\" for file in associated_files]) if associated_files else \"‚ùå Nessun file associato trovato.\"\n",
    "        html_content += format_html_section(\"üìÇ File Associati\", associated_files_section, color=\"red\")\n",
    "        \n",
    "        # Mostra il risultato come HTML\n",
    "        display(HTML(html_content))\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Si √® verificato un errore durante l'analisi dei metadati: {e}\")\n",
    "\n",
    "# Analizza e stampa i metadati del modello finale con metadati\n",
    "display_model_metadata(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36dc09c4-c9c9-4e08-9473-e0aed8dd52da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Metadati aggiunti a models/custom_model_with_metadata.tflite\n",
      "üìÇ Metadati salvati in: models/custom_model_with_metadata.json\n",
      "‚úÖ Metadati aggiunti a models/custom_model_quantized_with_metadata.tflite\n",
      "üìÇ Metadati salvati in: models/custom_model_quantized_with_metadata.json\n",
      "‚úÖ Metadati aggiunti a models/custom_model_float16_with_metadata.tflite\n",
      "üìÇ Metadati salvati in: models/custom_model_float16_with_metadata.json\n"
     ]
    }
   ],
   "source": [
    "# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Writes metadata and label file to the object detection models.\n",
    "\n",
    "Lo script originale fornito da TensorFlow √® stato modificato per mappare correttamente\n",
    "i metadati ai tensori di output nell'ordine corretto.\n",
    "\n",
    "Inoltre, lo script √® stato adattato per scrivere i metadati su tre modelli:\n",
    "    - Modello senza quantizzazione\n",
    "    - Modello con quantizzazione dinamica\n",
    "    - Modello con quantizzazione Float16\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import flatbuffers\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "from tflite_support import metadata as _metadata\n",
    "\n",
    "# File paths per i tre modelli convertiti\n",
    "MODELS = {\n",
    "    \"non_quantized\": \"models/custom_model.tflite\",\n",
    "    \"quantized_dynamic\": \"models/custom_model_quantized.tflite\",\n",
    "    \"quantized_float16\": \"models/custom_model_float16.tflite\",\n",
    "}\n",
    "\n",
    "LABEL_FILE = \"models/label_map.pbtxt\"\n",
    "\n",
    "class ModelSpecificInfo:\n",
    "    \"\"\"Holds information for an object detector.\"\"\"\n",
    "    def __init__(self, name, version, image_width, image_height, mean, std):\n",
    "        self.name = name\n",
    "        self.version = version\n",
    "        self.image_width = image_width\n",
    "        self.image_height = image_height\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "MODEL_INFO = ModelSpecificInfo(\n",
    "    name=\"PlateRecognizer\",\n",
    "    version=\"3.0\",\n",
    "    image_width=300,\n",
    "    image_height=300,\n",
    "    mean=[127.5],\n",
    "    std=[127.5])\n",
    "\n",
    "class MetadataPopulatorForObjectDetector:\n",
    "    \"\"\"Populates the metadata for an object detection model.\"\"\"\n",
    "\n",
    "    def __init__(self, model_file, export_model_file, model_info, label_file_path):\n",
    "        self.model_file = model_file\n",
    "        self.export_model_file = export_model_file\n",
    "        self.model_info = model_info\n",
    "        self.label_file_path = label_file_path\n",
    "        self.metadata_buf = None\n",
    "\n",
    "    def populate(self):\n",
    "        \"\"\"Creates metadata and then populates it for an object detection model.\"\"\"\n",
    "        self._create_metadata()\n",
    "        self._populate_metadata()\n",
    "\n",
    "    def _create_metadata(self):\n",
    "        \"\"\"Creates the metadata for an object detection model.\"\"\"\n",
    "\n",
    "        # Model metadata\n",
    "        model_meta = _metadata_fb.ModelMetadataT()\n",
    "        model_meta.name = self.model_info.name\n",
    "        model_meta.description = (\n",
    "            \"Identify objects in an image and provide their locations.\"\n",
    "        )\n",
    "        model_meta.version = self.model_info.version\n",
    "        model_meta.license = (\"Apache License. Version 2.0 \"\n",
    "                              \"http://www.apache.org/licenses/LICENSE-2.0.\")\n",
    "\n",
    "        # Input tensor metadata\n",
    "        input_meta = _metadata_fb.TensorMetadataT()\n",
    "        input_meta.name = \"image\"\n",
    "        input_meta.description = \"Input image to be detected.\"\n",
    "        input_meta.content = _metadata_fb.ContentT()\n",
    "        input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "        input_meta.content.contentProperties.colorSpace = _metadata_fb.ColorSpaceType.RGB\n",
    "        input_meta.content.contentPropertiesType = _metadata_fb.ContentProperties.ImageProperties\n",
    "        \n",
    "        input_normalization = _metadata_fb.ProcessUnitT()\n",
    "        input_normalization.optionsType = _metadata_fb.ProcessUnitOptions.NormalizationOptions\n",
    "        input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "        input_normalization.options.mean = self.model_info.mean\n",
    "        input_normalization.options.std = self.model_info.std\n",
    "        input_meta.processUnits = [input_normalization]\n",
    "\n",
    "        input_stats = _metadata_fb.StatsT()\n",
    "        input_stats.max = [255.0]\n",
    "        input_stats.min = [0.0]\n",
    "        input_meta.stats = input_stats\n",
    "\n",
    "        # Output tensors metadata\n",
    "        output_tensors = []\n",
    "\n",
    "        # Number of detections\n",
    "        num_detections_meta = _metadata_fb.TensorMetadataT()\n",
    "        num_detections_meta.name = \"number of detections\"\n",
    "        num_detections_meta.description = \"The number of detected plates.\"\n",
    "        num_detections_meta.content = _metadata_fb.ContentT()\n",
    "        num_detections_meta.content.contentProperties = _metadata_fb.FeaturePropertiesT()\n",
    "        num_detections_meta.content.contentPropertiesType = _metadata_fb.ContentProperties.FeatureProperties\n",
    "        output_tensors.append(num_detections_meta)\n",
    "\n",
    "        # Location (bounding boxes)\n",
    "        location_meta = _metadata_fb.TensorMetadataT()\n",
    "        location_meta.name = \"location\"\n",
    "        location_meta.description = \"The locations of the detected plates.\"\n",
    "        location_meta.content = _metadata_fb.ContentT()\n",
    "        location_meta.content.contentProperties = _metadata_fb.BoundingBoxPropertiesT()\n",
    "        location_meta.content.contentProperties.index = [1, 0, 3, 2]\n",
    "        location_meta.content.contentProperties.type = _metadata_fb.BoundingBoxType.BOUNDARIES\n",
    "        location_meta.content.contentPropertiesType = _metadata_fb.ContentProperties.BoundingBoxProperties\n",
    "        output_tensors.append(location_meta)\n",
    "\n",
    "        # Category\n",
    "        category_meta = _metadata_fb.TensorMetadataT()\n",
    "        category_meta.name = \"category\"\n",
    "        category_meta.description = \"The categories of the detected plates.\"\n",
    "        category_meta.content = _metadata_fb.ContentT()\n",
    "        category_meta.content.contentProperties = _metadata_fb.FeaturePropertiesT()\n",
    "        category_meta.content.contentPropertiesType = _metadata_fb.ContentProperties.FeatureProperties\n",
    "        output_tensors.append(category_meta)\n",
    "\n",
    "        # Score\n",
    "        score_meta = _metadata_fb.TensorMetadataT()\n",
    "        score_meta.name = \"score\"\n",
    "        score_meta.description = \"The confidence scores of the detected plates.\"\n",
    "        score_meta.content = _metadata_fb.ContentT()\n",
    "        score_meta.content.contentProperties = _metadata_fb.FeaturePropertiesT()\n",
    "        score_meta.content.contentPropertiesType = _metadata_fb.ContentProperties.FeatureProperties\n",
    "        output_tensors.append(score_meta)\n",
    "\n",
    "        # Associated label file\n",
    "        label_file = _metadata_fb.AssociatedFileT()\n",
    "        label_file.name = os.path.basename(self.label_file_path)\n",
    "        label_file.description = \"Labels for categories that the model can recognize.\"\n",
    "        label_file.type = _metadata_fb.AssociatedFileType.TENSOR_VALUE_LABELS\n",
    "        category_meta.associatedFiles = [label_file]\n",
    "\n",
    "        # Subgraph metadata\n",
    "        subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "        subgraph.inputTensorMetadata = [input_meta]\n",
    "        subgraph.outputTensorMetadata = output_tensors\n",
    "        model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "        # Generate metadata buffer\n",
    "        b = flatbuffers.Builder(0)\n",
    "        b.Finish(\n",
    "            model_meta.Pack(b),\n",
    "            _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "        self.metadata_buf = b.Output()\n",
    "\n",
    "    def _populate_metadata(self):\n",
    "        \"\"\"Populates metadata and label file to the model file.\"\"\"\n",
    "        populator = _metadata.MetadataPopulator.with_model_file(self.export_model_file)\n",
    "        populator.load_metadata_buffer(self.metadata_buf)\n",
    "        populator.load_associated_files([self.label_file_path])\n",
    "        populator.populate()\n",
    "\n",
    "def main():\n",
    "    for model_name, model_path in MODELS.items():\n",
    "        export_model_path = model_path.replace(\".tflite\", \"_with_metadata.tflite\")\n",
    "\n",
    "        # Copia il modello originale\n",
    "        tf.io.gfile.copy(model_path, export_model_path, overwrite=True)\n",
    "\n",
    "        # Popolazione dei metadati\n",
    "        populator = MetadataPopulatorForObjectDetector(\n",
    "            model_path, export_model_path, MODEL_INFO, LABEL_FILE)\n",
    "        populator.populate()\n",
    "\n",
    "        # Generazione file JSON con i metadati\n",
    "        displayer = _metadata.MetadataDisplayer.with_model_file(export_model_path)\n",
    "        export_json_file = export_model_path.replace(\".tflite\", \".json\")\n",
    "        with open(export_json_file, \"w\") as f:\n",
    "            f.write(displayer.get_metadata_json())\n",
    "\n",
    "        print(f\"‚úÖ Metadati aggiunti a {export_model_path}\")\n",
    "        print(f\"üìÇ Metadati salvati in: {export_json_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192b4c75-6207-4ce5-9da4-81e79d2028d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
